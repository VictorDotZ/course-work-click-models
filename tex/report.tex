\documentclass[diploma]{nanolab2015}

\usepackage{float}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{dcolumn}
\usepackage[flushleft]{threeparttable}
\usepackage{makecell}
\usepackage{enumitem}
\usepackage{xparse}
\usepackage{svg}
\newcounter{descriptcount}
\NewDocumentEnvironment{enumdescript}{O{}}{%
    \setcounter{descriptcount}{0}%
    \renewcommand*\descriptionlabel[1]{%
      \stepcounter{descriptcount}%
      \normalfont\bfseries ##1%
    }%
    \description%
  }%
  {\enddescription}



\DeclareMathOperator{\Attention}{Attention}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\ReLU}{ReLU}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\AdamW}{AdamW}


\begin{document}
\begin{titlepage}
    \begin{center}
        \large
        Федеральное государственное бюджетное образовательное учреждение
        высшего образования «Московский государственный университет имени
        М.В.Ломоносова»

        МЕХАНИКО-МАТЕМАТИЧЕСКИЙ ФАКУЛЬТЕТ

        \textbf{Кафедра Математической теории интеллектуальных систем}\\
        \vspace{4cm}
        \textsc{\Large Курсовая работа}\\[5mm]
        {\LARGE Исследование нейросетевых методов построения кликовой модели для задач информационного поиска}
    \end{center}
    \vspace{3cm}
    \null

    \begin{flushright}
        \normalsize \underline{Выполнил:}
        \\студент 531 группы
        \\Зенин В. О.
        \\ \underline{\hspace{4cm}}
    \end{flushright}
    \vspace{1cm}

    \begin{flushright}
        \normalsize \underline{Научный руководитель:}
        \\к.ф.-м.н., н.с Половников В. С.
        \\ \underline{\hspace{4cm}}
    \end{flushright}

    \vfill
    \begin{center}
        \textbf{Москва - 2024}
    \end{center}
\end{titlepage}
\setcounter{page}{3}
\clearpage
\tableofcontents{}  % оглавление
\clearpage
\chapter{Введение}
Информационные системы занимают центральное место в обработке больших объемов данных. С увеличением количества информации важно разрабатывать методы поиска, которые обеспечат пользователям быстрое нахождение нужной информации. Одним из важных источников данных являются действия пользователей при поиске и работе с найденной информацией. Исследуя подобные данные можно извлекать из них различные признаки, способные улучшать качество поисковой системы и лучше удовлетворять потребности пользователя.

Одним из способов работы с такими данными являются кликовые модели, которые анализируют имеющуюся историю взаимодействия пользователей с результатами поисковой выдачи и помогают лучше понять, какие из показанных документов были более или менее полезны. Традиционные подходы к построению кликовых моделей включают в себя различные вероятностные методы, однако с развитием технологий машинного обучения все более актуальным становятся нейросетевые методы, обладающие в некоторых задачах высокой обобщающей способностью, позволяющей эффективно обрабатывать и анализировать сложные и многомерные данные.

Актуальность данной темы обусловлена как практическими потребностями, так и научным интересом. С одной стороны, улучшение алгоритмов информационного поиска напрямую влияет на качество пользовательского опыта и способность поисковых систем решать свою главную задачу по нахождению релевантного контента. С другой стороны, исследование нейросетевых методов в контексте кликовых моделей открывает новые горизонты в области машинного обучения и обработки больших данных.

Целью данной работы является изучение современных нейросетевых методов построения кликовых моделей и их применения в задачах информационного поиска. В работе будут рассмотрены как теоретические аспекты разработки таких моделей, так и практические примеры их внедрения и оценки эффективности. Мы проанализируем существующие подходы, выявим их преимущества и недостатки, а также предложим возможные направления для дальнейших исследований и улучшений.
\newpage
\section{Основные понятия и терминология}
\subsection{Поисковая выдача}

Поисковая выдача — это набор результатов $D_i$, которые поисковая система представляет пользователю в ответ на его поисковый запрос. Результаты включают ссылки на различные документы $\{d_{i,1}, \dots, d_{i, M}\}$, которые поисковая система считает релевантными запросу пользователя.

Страницу результатов поиска, которую пользователь видит после ввода поискового запроса, принято называть серп, от SERP -- Search Engine Results Page. Серп обычно включает органические результаты (неоплаченные ссылки), платные результаты (рекламные ссылки), а также другие элементы, такие как изображения, видео, карты и фрагменты с ответами на вопросы.

\subsection{Пользовательская сессия}

Пользовательская сессия $S$ в контексте информационного поиска представляет собой последовательность взаимодействий пользователя с поисковой системой в течение определенного периода времени. В зависимости от контекста и целей анализа, можно выделить два типа сессий: сессии в широком смысле и сессии в узком смысле.

Сессия в широком смысле включает все действия пользователя, связанные с поиском информации, начиная с ввода первого поискового запроса $q_1$ и заканчивая завершением активности или истечением времени неактивности. В эту сессию входят все последующие перезапросы, изменения поисковых фраз, составляющие последовательность запросов $Q_N = {q_1, \dots, q_N}$, а также клики $C = \{c_{i,j}\}$ на результаты поиска, переходы по ссылкам и возвращения на страницу поиска.

Сессия в узком смысле ограничивается взаимодействием пользователя в рамках одного конкретного поискового запроса $q$. В нее входят действия, связанные только с этим запросом.

Не трудно заметить, что сессия в широком смысле является множеством сессий в узком смысле и может быть на них разбита. Обратное же не верно, поскольку заданные в разное время пользовательские запросы могут не относится к удовлетворению его конкретной информационной потребности.

Действия пользователя зависят от типа показанного контента и не ограничиваются только кликами. Каждый тип принято называть вертикалью поиска. Например, если поисковая система показала видео в серпе, то гораздо важнее знать сколько времени пользователь его смотрел или досмотрел ли до конца.

\subsection{Релевантность}
Релевантность обозначает степень соответствия между поисковым запросом пользователя и предоставленными поисковой системой результатами. Чем выше степень соответствия между запросом и результатами, тем более релевантными считаются эти результаты для пользователя.

Иными словами, релевантность показывает, насколько хорошо результат поиска отвечает на запрос пользователя и удовлетворяет его информационные потребности. Это не только соответствие ключевым словам в запросе и содержанию документа, но и более общие факторы, такие как тематика, контекст и цель запроса.

Для оценки релевантности составляется специальная инструкция, по которой эксперты (асессоры) оценивают пары запрос-документ и выставляют каждому из них оценку -- как правило это неотрицательное целое число.

Когда каждой паре запрос-документ сопоставлена такая численная оценка релеватности документа по этому запросу $rel$, можно оценить качество алгоритма ранжирования вычислив $DCG$ -- Discounted Cumulative Gain по формулам:
\begin{align}
    DCG@N = \sum_{i=1}^{N} \frac{rel_i}{log_2(i+1)}
\end{align}
или
\begin{align}
    DCG@N = \sum_{i=1}^{N} \frac{2^{rel_i} - 1}{log_2(i+1)}
\end{align}
где $N$ -- количество документов в выдаче, $i$ - позиция документа и $rel_i$ -- его релевантность. Можно заметить, что релевантные документы, оказавшиеся на последних позициях, дают малый вклад. Также как малый вклад дают и нерелевантные документы, оказавшиеся на первых позициях.

Существует способ нормализации $DCG$, приводящий её значения в диапазон от 0 до 1, заключающийся в вычислении $IDCG$ -- Ideal DCG. $IDCG$ это максимальное значение $DCG$ для данного запроса, но используя те же самые документы, т.е. все документы должны быть отсортированы в порядке убывания их релевантности. После чего нормализованный $DCG$, называющийся $nDCG$ вычисляется как отношение $DCG$ к соответствующему ему $IDCG$. Поскольку так оценивается выдача по одному запросу, для оценки по группе запросов берётся среднее арифметическое.

\subsection{Кликовая модель}
Кликовая модель в классическом понимании -- это статистическая модель, которая предсказывает вероятность того, что пользователь совершит клик по определенному результату в поисковой выдаче, основываясь на исторических данных о кликах пользователей.

В отличии от других областей, например рекомендательных технологий, в поиске ключевым элементом является запрос и пользовательские сессии агрегируются по нему.

\subsection{Позиционная предвзятость}
Позиционная предвзятость -- это явление, при котором вероятность клика на определенный результат поисковой выдачи зависит не только от релевантности документа, но и от позиции этого документа в списке результатов. Результаты, которые находятся выше на странице выдачи, получают больше кликов независимо от их фактической релевантности, поскольку пользователи склонны кликать на первые несколько ссылок, не анализируя их подробно.

\section{Традиционные методы построения кликовых моделей}
В данном разделе мы последовательно рассмотрим некоторые методы, двигаясь от более простых к более сложным и каждый последующий метод будет учитывать недостатки предыдущего.
\subsection{CTR}
CTR (Click-Through Rate) — это метрика, используемая для измерения эффективности рекламы, поисковых результатов и других элементов, привлекающих клики. % метрика плохое слово, мы математики и это может сбить с толку

CTR рассчитывается как отношение количества кликов на определенный элемент (например, рекламное объявление или результат поиска) к количеству его показов. Формула для расчета CTR выглядит следующим образом:
\begin{align}
    CTR = \frac{clicks}{imps},
\end{align}
где $clicks$ -- количество кликов по документу который пользователь видел и $imps$ -- количество показов данного элемента пользователю.

Для использования в поиске важно, чтобы клики и показы документов происходили в рамках одного запроса. Таким образом высокий CTR документа указывает на то, что пользователи чаще кликают по нему в контексте данного запроса, что предполагает его высокую релевантность и полезность. CTR может использоваться как дополнительный фактор в алгоритме ранжирования поисково движка, который, при прочих равных, стремился бы продвигать документы с высокой кликабельностью выше в выдаче.

Для сессий в широком смысле в качестве такого запроса можно использовать самый первый, исходя из предположения, что пользователь совершает перезапросы с целью уточнить первоначальный и найти в конечном итоге то, что у него получилось с первого раза. Поскольку сессия в широком смысле содержит в себе несколько сессий в узком смысле, то CTR можно считать и по каждой такой сессии с уникальным запросом.

CTR обладает рядом существенных недостатков, среди самых важных можно выделить два: неустойчивость перед позиционной предвзятостью и злоупотреблением привлекательными заголовками. В первом случае высокий CTR будут получать документы на первых позициях в выдаче вне зависимости от их фактической релевантности. Во втором -- пользователя может заинтересовать непосредственно заголовок, в то время как сам документ покажется ему бесполезным и он быстро завершит его просмотр.

\subsection{ClickRank}
Данных метод применяется к сессиям в широком смысле и позволяет учесть проводимое пользователем на странице время. ClickRank \cite{clickrank} вычисляется по следующей формуле:
\begin{align}
    ClickRank(p_i, s_j) = \sum_{p_i \in s_j} w_r(i, s_j) w_t(p, s_j) I(p=p_i)
\end{align}

Опишем подробнее каждую компоненту данного выражения. $p_i$ -- в общем случае событие посещения веб-страницы. Поскольку документы в интернете, в общем случае, посещаются посредством совершения клика, можно считать это событием клика. $s_j$ -- сессия (в широком смысле), в которой данное событие клика произошло. $I$ -- индикатор. Весовые функции $w_r$ и $w_t$ отвечают за порядок клика и проведенное на странице время соответственно.
\begin{align}
    w_r(i, s_j) = \frac{2(n_j + 1 - r(i))}{n_j(n_j + 1)},
\end{align}
где $r(i) \in \{1, \dots, n_j\}$ -- порядковый номер события клика в сессии, а $n_j$ -- количество событий в сессии (её длина). Функция является монотонно убывающей по $r(i)$, что позволяет ей давать больший вес для кликнутых ранее документов. Поскольку пользователи кликают на документы из начала серпа раньше, данный метод не борется с позиционной предвзятостью. Однако он позволяет учитывать проводимое время посредством второй весовой функции:
\begin{align}
    w_t(p, s) = (1 - e^{-\lambda_1 t_d})e^{-\lambda_2 t_l} I(t(p) \in \mathcal{T}),
\end{align}
где $t_d$ -- время, проведенное на странице (для удобства оно может быть некоторым образом нормализовано, а способ нормализации лучше выбирать исходя из природы данных и подбирать, используя кросс-валидацию) $t_l$ -- время загрузки страницы (часто можно положить его равным нулю, исходя из предположения, что пользователь проводит на странице намного больше времени, чем она загружается). Коэффициенты $\lambda_1$ и $\lambda_2$ также являются гиперпараметрами и могут быть подобраны под конкретные данные. $I$ -- индикатор, определяющий интересующий нас временной интервал -- тот, к которому относится рассматриваемое событие клика $p$.

Также стоит отметить, что весовая функция для проводимого времени достаточно гибкая и зависит от предполагаемого распределения проводимого времени на странице. В приведенной формуле используется предположения о распределение Пуассона, но на некоторых данных лучшие результаты может показать, например, распределение Вейбулла.

Как правило, если пользователь завершил сессию на просмотре какого-то документа и не вернулся в поиск, то нельзя достоверно установить проведенное время. Это вынуждает нас предполагать, что оно бесконечно и, соответственно, последний кликнутый пользователем документ самый важный. Зачастую это не так, поскольку пользователь мог не найти удовлетворяющего его информационную потребность контента вовсе, что и послужило мотивом для завершения сессии.

Для поиска необходимо аккумулировать ClickRank. В качестве запроса возьмем первый запрос в сессии (в широком смысле) и посчитаем суммарный ClickRank документов, по которым в сессиях с идентичным первым запросом совершались клики. Каждую такую сумму необходимо поделить на количество кликов по соответствующему документу, что даст средний ClickRank для каждого документа в контексте конкретного запроса. Это число можно использовать в качестве одного из факторов ранжирования.

Метод позволяет алгоритму ранжирования поднимать выше документы, на которые пользователи кликают и где проводят больше всего времени, но никак не борется с позиционной предвзятостью.

\subsection{DBN}
Dynamic Bayesian Network (DBN) представляет собой расширение байесовских сетей, которое учитывает временные зависимости между переменными. В контексте кликовых моделей для задач информационного поиска DBN используется для моделирования последовательности кликов пользователя на результаты поиска, а временная зависимость представляет собой предположение о том, что пользователь просматривает результаты поисковой выдачи от первого к последнему, последовательно обращая внимание на каждый документ и некоторым образом с ним взаимодействуя.

Модель на основе DBN учитывает \cite{DBN}, что вероятность клика на результат поиска зависит от его позиции в выдаче. Также модель принимает во внимание вероятность того, что пользователь в принципе заметит и решит кликнуть на документ в выдаче, а после -- продолжит просмотр других результатов.

DBN применяется для действий пользователя с результатом поисковой выдачи по одному запросу, то есть для сессий в узком смысле. Модель задается уравнениями:
\begin{align}
    A_i = 1, E_i = 1                  & \Leftrightarrow C_i = 1 \label{dbn:1} \\
    P(A_i = 1)                        & = a_u                  \label{dbn:2}  \\
    P(S_i = 1| C_i = 1)               & = s_u                   \label{dbn:3} \\
    C_i = 0                           & \Rightarrow S_i = 0 \label{dbn:4}     \\
    S_i = 1                           & \Rightarrow E_{i+1} = 0 \label{dbn:5} \\
    P(E_{i+1} = 1 | E_i = 1, S_i = 0) & = \gamma                \label{dbn:6} \\
    E_i = 0                           & \Rightarrow E_{i+1} = 0 \label{dbn:7}
\end{align}


где $E, A, C, S$ -- случайные события:
\begin{itemize}
    \item $E_i$: заметил ли пользователь документ на позиции $i$
    \item $A_i$: привлек ли данный документ его внимание
    \item $C_i$: кликнул ли он на этот документ
    \item $S_i$: была ли удовлетворена информационная потребность пользователя
\end{itemize}
Тогда уравнения можно интерпретировать следующим образом:
\begin{itemize}
    \item (\ref{dbn:1}): Пользователь кликает на документ тогда и только тогда если он его заметил и тот привлек его внимание
    \item (\ref{dbn:2}): Привлекательность документа зависит только от него самого
    \item (\ref{dbn:3}): Удовлетворенность пользователя кликнутым документом имеет некоторую вероятность
    \item (\ref{dbn:4}): Если пользователь не кликнул на документ, то его информационная потребность не была удовлетворена этим документом
    \item (\ref{dbn:5}): Если же документ $i$ удовлетворил пользователя, то он не замечает следующего за ним документа
    \item (\ref{dbn:6}): С некоторой вероятностью пользователь продолжит просмотр выдачи и заметит следующий документ, если остался не удовлетворен предыдущим
    \item (\ref{dbn:7}): Если пользователь не заметил документ, то и все последующие он не заметит
\end{itemize}

Вероятности $a_u$ и $s_u$ полагаются равными нулю и являются, по мере обновления, результатом обучения такой модели на исторических данных при заданной вероятности $\gamma$, которая, в свою очередь, уже является гиперпараметром и требует определения. Обычно её можно подобрать максимизируя $CTR$ документа на первой позиции. У авторов подхода лучшие результаты получаются при $\gamma = 0.9$, но простое предположение о $\gamma = 1$ приводит к результатам не сильно хуже, позволяя, при этом, упростить вычисления.

Используя для вычисления сессии всех пользователей, задавший определенный запрос, $a_u$ и $s_u$ каждого документа по данному запросу можно использовать далее как признаки для модели ранжирования.

Данный метод нивелирует описанные в других методах недостатки и является широко используемым не только в поиске, но и, например, в рекомендациях: ключевым отличием является то, что в поиске оценка $\gamma$ одинакова для всех пользователей, в то время как в рекомендациях -- каждый пользователь может иметь свою оценку. Однако, его трудно применять для сессий в широком смысле: не смотря на то, что для каждого запроса можно соединить результаты всех последующих перезапросов в одну выдачу, это увеличит вычислительную сложность, но может не привести к ощутимому росту качества.

Также данный метод не учитывает реальную последовательность пользовательских действий: если пользователь кликнул по двум документам, причем первый клик пришелся на документ с большей позицией, то для модели всё будет ровно наоборот. Предположение о том, что пользователь просматривает документы исключительно сверху вниз и по порядку достаточно строгое.

\chapter{Основная часть}
\section{Формальная постановка задачи}

\section{Данные}


\section{Методы}

\section{Эксперимент}
\subsection{Результаты}


\chapter{Заключение}

\begin{thebibliography}{00}
    \bibitem{clickrank}
    Guangyu Zhu and Gilad Mishne. 2012. ClickRank: Learning Session-Context Models to Enrich Web Search Ranking. ACM Trans. Web 6, 1, Article 1 (March 2012), 22 pages. https://doi.org/10.1145/2109205.2109206
    \bibitem{DBN}
    Olivier Chapelle and Ya Zhang. 2009. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th international conference on World wide web (WWW '09). Association for Computing Machinery, New York, NY, USA, 1–10. https://doi.org/10.1145/1526709.1526711
\end{thebibliography}

\end{document}
